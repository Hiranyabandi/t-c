{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8edcpLWd03Y2",
        "outputId": "9d520f31-9097-43d0-e448-976c9a56e41a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Status Code: 200\n",
            "Response: {'response': 'Error generating response.'}\n"
          ]
        }
      ],
      "source": [
        "# import os\n",
        "# import requests\n",
        "# import json\n",
        "\n",
        "# # Retrieve the API key from the environment\n",
        "# api_key = os.getenv(\"DSBA_LLAMA3_KEY\")\n",
        "\n",
        "# API_URL = \"https://lasyaed--vllm-openai-compatible-serve.modal.run/rag-query\"  # Replace with your actual URL\n",
        "\n",
        "# def test_rag_query(query):\n",
        "#     headers = {\n",
        "#         \"Content-Type\": \"application/json\",\n",
        "#         \"Authorization\": f\"Bearer {api_key}\"  # Use the API key from environment variable\n",
        "#     }\n",
        "#     data = json.dumps({\"query\": query})\n",
        "\n",
        "#     try:\n",
        "#         response = requests.post(API_URL, headers=headers, data=data)\n",
        "#         print(f\"Status Code: {response.status_code}\")\n",
        "#         if response.status_code == 200:\n",
        "#             print(\"Response:\", response.json())\n",
        "#         else:\n",
        "#             print(\"Error Message:\", response.text)\n",
        "#     except Exception as e:\n",
        "#         print(f\"Failed to communicate with the server: {e}\")\n",
        "\n",
        "# test_rag_query(\"Explain METTLER TOLEDO's intellectual property policy.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu\n",
        "!pip install openai==0.28.0\n",
        "!pip install python-dotenv\n",
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-Vsalsrp5Hfb",
        "outputId": "4b2c468f-f36a-4af0-9bf4-d55275e8d88f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.9.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n",
            "Collecting openai==0.28.0\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28.0) (4.66.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28.0) (3.10.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.0) (2024.8.30)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28.0) (4.12.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->openai==0.28.0) (0.2.0)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.52.2\n",
            "    Uninstalling openai-1.52.2:\n",
            "      Successfully uninstalled openai-1.52.2\n",
            "Successfully installed openai-0.28.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "openai"
                ]
              },
              "id": "c608bede2d3b47118af860cf7448ad91"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.44.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.0+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.24.7)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import openai\n",
        "import os\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from google.colab import userdata\n",
        "\n",
        "# Load the embedding model\n",
        "embedding_model_name = \"all-MiniLM-L6-v2\"  # Example embedding model\n",
        "embedding_model = SentenceTransformer(embedding_model_name)\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Load FAISS index\n",
        "index_path = \"faiss_index.bin\"\n",
        "faiss_index = faiss.read_index(index_path)\n",
        "\n",
        "# Load filename_mapping.txt for metadata\n",
        "def load_filename_mapping(file_path):\n",
        "    context_dict = {}\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split(\"\\t\")\n",
        "            if len(parts) == 5:  # Assumes structure: \"idx\\tdoc_id\\tsection_title\\tsubsection\\tfile_name\"\n",
        "                idx, doc_id, section_title, subsection, file_name = parts\n",
        "                context_dict[int(idx)] = {\n",
        "                    \"Document ID\": doc_id,\n",
        "                    \"Section Title\": section_title,\n",
        "                    \"Subsection\": subsection,\n",
        "                    \"File Name\": file_name\n",
        "                }\n",
        "    return context_dict\n",
        "\n",
        "# Create combined context by appending document content with metadata\n",
        "def create_combined_context(context_dict, indices):\n",
        "    combined_context = \"\"\n",
        "    for idx in indices:\n",
        "        entry = context_dict.get(idx)\n",
        "        if entry:\n",
        "            file_path = f\"data/{entry['File Name']}\"  # Assumes documents are stored in 'data/' directory\n",
        "            try:\n",
        "                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                    content = f.read()\n",
        "                # Append content with metadata for clarity\n",
        "                combined_context += (\n",
        "                    f\"Document ID: {entry['Document ID']}\\n\"\n",
        "                    f\"Section Title: {entry['Section Title']}\\n\"\n",
        "                    f\"Subsection: {entry['Subsection']}\\n\"\n",
        "                    f\"Content:\\n{content}\\n\\n\"\n",
        "                )\n",
        "            except FileNotFoundError:\n",
        "                print(f\"Warning: {file_path} not found.\")\n",
        "    return combined_context\n",
        "\n",
        "# Function to embed query, retrieve similar documents, and generate response with ChatGPT\n",
        "def generate_response_with_context(query, top_k=2, model=\"gpt-3.5-turbo\", temperature=0.7):\n",
        "    # Embed the query\n",
        "    query_embedding = embedding_model.encode(query).reshape(1, -1)\n",
        "\n",
        "    # Retrieve similar documents using FAISS\n",
        "    distances, indices = faiss_index.search(query_embedding, top_k)\n",
        "    print(\"Retrieved document indices:\", indices[0])  # Display indices of retrieved documents\n",
        "\n",
        "    # Load filename_mapping.txt and retrieve combined context for top_k documents\n",
        "    filename_mapping_path = \"filename_mapping.txt\"\n",
        "    context_dict = load_filename_mapping(filename_mapping_path)\n",
        "    combined_context = create_combined_context(context_dict, indices[0])\n",
        "\n",
        "    # Create messages for the ChatCompletion call\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"Use the provided information to answer the question.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Context:\\n{combined_context}\\n\\nQuestion:\\n{query}\"}\n",
        "    ]\n",
        "\n",
        "    # Call OpenAI API with the combined context\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=model,\n",
        "            messages=messages,\n",
        "            max_tokens=200,\n",
        "            temperature=temperature\n",
        "        )\n",
        "        return response.choices[0].message['content'].strip()  # Return the generated response text\n",
        "    except Exception as e:\n",
        "        print(f\"Error calling OpenAI API: {e}\")\n",
        "        return None\n",
        "\n"
      ],
      "metadata": {
        "id": "tNrwxfs_6CBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the function with a sample query\n",
        "sample_query = \"Does METTLER TOLEDO's waive any provision?\"\n",
        "response = generate_response_with_context(sample_query)\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHdQKRLUAW-j",
        "outputId": "49be32d1-1207-47b7-d496-a7c8a73ad481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved document indices: [316 307]\n",
            "No, METTLER TOLEDO does not waive any provision.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_query = \"Does METTLER TOLEDO provide products and services in all countries?\"\n",
        "response = generate_response_with_context(sample_query)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beOQ8TOoAh9v",
        "outputId": "5650d3a7-670d-43d0-aa66-63191f64767b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved document indices: [295 282]\n",
            "No, METTLER TOLEDO does not provide products and services in all countries. The company operates in various countries worldwide, but its product availability and service offerings may vary depending on the region.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_query = \"how to submit a contest entry for BurgerKing?\"\n",
        "response = generate_response_with_context(sample_query)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKjoZwW7jM8o",
        "outputId": "5ee57853-a900-4b86-94e5-fc20c004b4a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved document indices: [85 82]\n",
            "To submit a contest entry for Burger King, you typically need to follow the guidelines and requirements set by the specific contest. This can usually be found on the Burger King website or on their social media channels where the contest is being promoted. Here are some general steps you might need to take:\n",
            "\n",
            "1. Visit the Burger King website or their official social media pages to find the contest details.\n",
            "2. Read the rules and regulations of the contest carefully to understand the requirements for the entry.\n",
            "3. Create your contest entry according to the guidelines provided. This could involve submitting a photo, video, written content, or any other form of entry specified by the contest rules.\n",
            "4. Submit your entry through the designated method, which could be through the contest website, social media platform, or via email.\n",
            "5. Make sure to meet the deadline for submission and adhere to any other instructions provided.\n",
            "\n",
            "Remember, the specific steps may vary depending on the contest, so always refer to the official rules and guidelines for accurate information\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_query = \"What personal information does Bank of America access from my wireless account to prevent fraud?\"\n",
        "response = generate_response_with_context(sample_query)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GZvkuTfkcZ3",
        "outputId": "44cf62d1-227c-4f89-f306-0cc20fcba582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved document indices: [269 271]\n",
            "Bank of America accesses the following personal information from your wireless account to prevent fraud:\n",
            "\n",
            "1. Location information\n",
            "2. Phone number\n",
            "3. Device information\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_query = \"What information might my wireless operator disclose to Bank of America or Zelle® when I use their service?\"\n",
        "response = generate_response_with_context(sample_query)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_UmY3kQl5ey",
        "outputId": "14fa740c-d7de-4d8f-8943-eaf992c3c154"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved document indices: [269 184]\n",
            "When you use a wireless operator's service to make transactions through Bank of America or Zelle®, the wireless operator may disclose information such as your phone number, location data, device information, and details of the transactions to facilitate the service and ensure its security. This information is typically shared in accordance with the wireless operator's privacy policy and in compliance with relevant laws and regulations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_query = \"Are third-party delivery services covered by the Chick-fil-A One rewards program?\"\n",
        "response = generate_response_with_context(sample_query)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlYIPIpfmgUD",
        "outputId": "b53a4948-6cd7-4afb-ffaf-67be1dd7705d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved document indices: [ 71 345]\n",
            "Yes, Chick-fil-A One rewards program covers orders placed through third-party delivery services as long as the account is linked to the delivery platform.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_query = \"Does Chick-fil-A's Terms and Conditions allow class action lawsuits?\"\n",
        "response = generate_response_with_context(sample_query)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgoW_Vkkmjj0",
        "outputId": "ffa9b8f4-8b84-4b60-882d-519702eda900"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved document indices: [ 33 374]\n",
            "Chick-fil-A's Terms and Conditions do not allow class action lawsuits.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_query = \"Can I redeem my Chick-fil-A One points at all locations?\"\n",
        "response = generate_response_with_context(sample_query)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvQCsJz7mkCl",
        "outputId": "aabe4201-c8db-4d2d-9043-f798907445d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved document indices: [23 74]\n",
            "Yes, you can redeem your Chick-fil-A One points at all participating Chick-fil-A locations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_query = \"What is Chick-fil-A's policy on gift offers and digital rewards?\"\n",
        "response = generate_response_with_context(sample_query)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnFlfNkQmk1h",
        "outputId": "d10f6d67-8d20-4d86-b702-c42f93c1a3c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved document indices: [347 350]\n",
            "Chick-fil-A has a policy that allows customers to earn free food through their Chick-fil-A One rewards program. Customers can earn points for each purchase made, and once a certain number of points is reached, they can redeem them for free food items. Chick-fil-A also occasionally offers digital rewards and promotions to their customers through the Chick-fil-A One app. Customers can check the app for special offers and promotions available to them.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_query = \"What are OpenAI's restrictions on using generated output for commercial purposes?\"\n",
        "response = generate_response_with_context(sample_query)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sp0tNS3OmlOf",
        "outputId": "5dbaa68c-3642-4beb-b1c5-4d9fe21cecbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved document indices: [12 16]\n",
            "OpenAI's GPT-3 API terms of use state that users are not allowed to use the generated output for commercial purposes unless they have received written approval from OpenAI. This restriction is in place to prevent misuse of the technology for potential harm or unethical purposes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_query = \"Can I use ChatGPT's output to develop competing AI models?\"\n",
        "response = generate_response_with_context(sample_query)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULgDIdpOml3k",
        "outputId": "99d6434e-0462-4f12-b1e4-930c0298b688"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved document indices: [107 351]\n",
            "No, you cannot use ChatGPT's output to develop competing AI models. The output generated by ChatGPT is protected by copyright laws and is intended for personal, non-commercial use only. Developing competing AI models using ChatGPT's output would be a violation of the terms of service and copyright laws.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_query = \"Under what conditions would I be required to seek an additional license from Meta if I intend to commercially distribute products utilizing Llama 2 outputs?\"\n",
        "response = generate_response_with_context(sample_query)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIgH0SDPmmWa",
        "outputId": "03fbc961-9805-4353-8516-a775deebf1e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved document indices: [121 123]\n",
            "If you intend to commercially distribute products utilizing Llama 2 outputs, you would be required to seek an additional license from Meta if you plan to include any proprietary technology or intellectual property owned by Meta in your products. This is because using Meta's proprietary technology or intellectual property for commercial purposes may require a separate license agreement to ensure compliance with Meta's terms and conditions. It is important to review Meta's licensing policies and agreements to understand your obligations and requirements when incorporating Llama 2 outputs into your commercial products.\n"
          ]
        }
      ]
    }
  ]
}